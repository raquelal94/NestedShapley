{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "The following jupyter notebook contains the computation for the Nested Shapley values included in the appendix example in the paper Alonso et al. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2b8cbecceabf538"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from src.NestedShapley import create_Ci_list, get_VS_matrix, create_N_M_list, get_Ci_matrix, get_NM_matrix, get_shapley_node, get_approx_shapley_node, associate_shapley_agent\n",
    "from src.ClusteringAlgorithm import SilhouetteScoreRange, GenerateArray, KMeansAlgorithm\n",
    "from src.appendix_model import model_p2p\n",
    "import pytz\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Directory with data\n",
    "current_directory = os.path.normpath(os.path.join(os.getcwd(), \"..\"))\n",
    "file_path_data = os.path.join(current_directory,r\"data_appendix\")\n",
    "\n",
    "# Input data\n",
    "start_date_str = \"2019-6-11\"\n",
    "end_date_str = \"2019-6-12\"\n",
    "\n",
    "N=12 # number of agents\n",
    "\n",
    "np.random.seed(42)  # You can choose any number as a seed\n",
    "houses_pv = np.random.choice(range(1, N + 1), int(N/2+2), replace=False)\n",
    "houses_pv = [f\"{i}\" for i in houses_pv]\n",
    "\n",
    "houses_bat = ['12', '10', '8', '9']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6bc524e3679f97f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import and preprocess the demand data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2917cf8ee5b58748"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def import_demand(file_demand,N):\n",
    "    date_format_str = '%Y-%m-%d %H:%M:%S%z'  # '2019-12-06 14:00:00+00:00' format\n",
    "    demand = pd.read_csv(file_demand, index_col=0,\n",
    "                         parse_dates=[0], date_format=date_format_str)\n",
    "\n",
    "    utc_tz = pytz.UTC  # just used to ensure matching the dates with the index\n",
    "    start_date = pd.to_datetime(start_date_str, format='%Y-%m-%d').tz_localize(utc_tz)\n",
    "    end_date = pd.to_datetime(end_date_str, format='%Y-%m-%d').tz_localize(utc_tz)\n",
    "    demand.index = demand.index.to_pydatetime()\n",
    "    demand = demand[demand.columns[:N]]\n",
    "    demand = demand[(demand.index >= start_date) & (demand.index < end_date)]\n",
    "    \n",
    "    return demand\n",
    "    \n",
    "file_demand = os.path.join(file_path_data,\"demand_Jan_365days.csv\")\n",
    "demand = import_demand(file_demand,N)\n",
    "demand_array, demand_ = GenerateArray(demand)\n",
    "demand_.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d0ccbae387fed7a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8292a34d0e0a373"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def agents_preprocessing(dataKMeans):\n",
    "    agent_list = [] #index identifies the number of the agent, value identifies the name of the agent\n",
    "    # dataKMeans_sorted = dataKMeans.sort_values(by='predicted cluster', ascending=True)\n",
    "    for i in dataKMeans[\"predicted cluster\"].unique():\n",
    "        df_ = dataKMeans[dataKMeans[\"predicted cluster\"]==i]\n",
    "        agent_list.extend(df_.index.to_list())\n",
    "\n",
    "    # check how many agents in each node\n",
    "    agents = dataKMeans[\"predicted cluster\"].value_counts().to_numpy()\n",
    "\n",
    "    return agent_list, agents\n",
    "\n",
    "def generate_data_dict_case_1(file_path_data, start_date_str, end_date_str, demand, current_agents, houses_pv, houses_bat):\n",
    "    list_houses = current_agents.copy()\n",
    "\n",
    "    list_houses_pv = [i for i in houses_pv if i in list_houses]\n",
    "    capacity_pv = list(np.full(len(list_houses_pv), 5))\n",
    "    list_houses_bat = [i for i in houses_bat if i in list_houses]\n",
    "\n",
    "    # transforming dates to align with data\n",
    "    utc_tz = pytz.UTC  # just used to ensure matching the dates with the index\n",
    "    start_date = pd.to_datetime(start_date_str, format='%Y-%m-%d').tz_localize(utc_tz)\n",
    "    end_date = pd.to_datetime(end_date_str, format='%Y-%m-%d').tz_localize(utc_tz)\n",
    "\n",
    "    # Get spot prices\n",
    "    date_format_str = '%Y-%m-%d %H:%M:%S%z'  # '2019-12-06 14:00:00+00:00' format\n",
    "    file_path = os.path.join(file_path_data, r\"dayahead_Jan_365days.csv\")\n",
    "    P_spot_df = pd.read_csv(file_path, index_col=0,\n",
    "                            parse_dates=[0], date_format=date_format_str)  # to make sure the date is read properly\n",
    "    P_spot_df.index = P_spot_df.index.to_pydatetime() # convert to a datetime format required for the model\n",
    "    P_spot_df = P_spot_df[[\"day ahead price (p/kWh)\"]]  # get only price in pences/kWh\n",
    "    P_spot_df_ = P_spot_df[(P_spot_df.index >= start_date) & (P_spot_df.index < end_date)]\n",
    "    # Convert the dataframe P_spot_df_ to dictionary for data input for the function model_p2p()\n",
    "    P_spot = P_spot_df_.to_dict()\n",
    "\n",
    "    # Get demand\n",
    "    demand_ = demand[list_houses]  # Filter based on the houses selected\n",
    "    demand_ = demand_.stack()  # Set time and household as index\n",
    "    # Convert the dataframe to dictionary\n",
    "    P_demand = demand_.to_dict()\n",
    "\n",
    "    # Get solar profiles, we assume the PV profile is the same for each house given that they are located close to each other\n",
    "    file_path = os.path.join(file_path_data, r\"solar_profile_scenarios_yearly.csv\")\n",
    "    PV_df = pd.read_csv(file_path, index_col=0,\n",
    "                        parse_dates=[0], date_format=date_format_str)\n",
    "    PV_df.index = PV_df.index.to_pydatetime() # convert to a datetime format required for the model\n",
    "    scn = \"1\"\n",
    "    PV_df = PV_df[[scn]]  # Select just one scenario, the data is prepared for several scenarios\n",
    "    PV_df_ = PV_df[(PV_df.index >= start_date) & (PV_df.index < end_date)]\n",
    "    # Convert the dataframe to dictionary\n",
    "    PV = PV_df_.to_dict()\n",
    "\n",
    "    # Set T\n",
    "    list_T = P_spot_df_.index.to_list()\n",
    "\n",
    "    # Parameter PV_cap\n",
    "    PV_cap = {f\"{key}\":capacity_pv[i] for i, key in enumerate(list_houses_pv)}\n",
    "\n",
    "    # Scalars (single value parameters)\n",
    "    Psi = 1 - 0.076  # Losses (assume a loss of 7.6% through the local network, Luth)\n",
    "    Mu_c = 0.96  # Charging efficiency\n",
    "    Mu_d = 0.96  # Discharging efficiency\n",
    "    Alpha = 1.5  # charging rate 2.5 kW -> 1.25 kWh/hour at constant rate\n",
    "    Beta = 1.5  # discharging rate 2.5 kW -> 1.25 kWh/hour at constant rate\n",
    "    Smax = 4  # capacity batteries [kWh] # It can also be changes to be similar to parameter PV_cap where you specify the capacity of each battery\n",
    "    Smin = Smax * 0.2  # minimum state of charge of batteries at all times\n",
    "    S_init = Smax * 0.5  # initial state of charge of the battery\n",
    "    c_FFR = 1000\n",
    "\n",
    "    # Construct data dictionary\n",
    "    data = {  # always start with None and then dictionary\n",
    "        None: {  # names of the keys equal to the name of the parameteres in the model\n",
    "            'H': {None: list_houses},  # providing data for set H\n",
    "            'H_pv': {None: list_houses_pv},  # providing data for set H_pv\n",
    "            \"H_bat\": {None: list_houses_bat},  # providing data for set H_bat\n",
    "            \"T\": {None: list_T},  # providing datetime for set T\n",
    "            # Parameters\n",
    "            'P_spot': P_spot['day ahead price (p/kWh)'],\n",
    "            \"PV\": PV[scn],\n",
    "            \"PV_cap\": PV_cap,\n",
    "            \"Dem\": P_demand,\n",
    "            # Scalars\n",
    "            \"Psi\": {None: Psi},\n",
    "            \"Mu_c\": {None: Mu_c},\n",
    "            \"Mu_d\": {None: Mu_d},\n",
    "            \"Alpha\": {None: Alpha},\n",
    "            \"Beta\": {None: Beta},\n",
    "            \"Smax\": {None: Smax},\n",
    "            \"Smin\": {None: Smin},\n",
    "            \"S_init\": {None: S_init},\n",
    "            \"c_FFR\": {None: c_FFR}\n",
    "        }}\n",
    "\n",
    "    return data\n",
    "\n",
    "def generate_data_dict_case_2(file_path_data, start_date_str, end_date_str, demand, current_agents):\n",
    "    list_houses = current_agents.copy()\n",
    "\n",
    "    list_houses_pv = list_houses.copy()\n",
    "    capacity_pv = list(np.full(len(list_houses_pv), 5)) # Capacity of 5\n",
    "    list_houses_bat = list_houses.copy()\n",
    "\n",
    "    # transforming dates to align with data\n",
    "    utc_tz = pytz.UTC  # just used to ensure matching the dates with the index\n",
    "    start_date = pd.to_datetime(start_date_str, format='%Y-%m-%d').tz_localize(utc_tz)\n",
    "    end_date = pd.to_datetime(end_date_str, format='%Y-%m-%d').tz_localize(utc_tz)\n",
    "\n",
    "    # Get spot prices\n",
    "    date_format_str = '%Y-%m-%d %H:%M:%S%z'  # '2019-12-06 14:00:00+00:00' format\n",
    "    file_path = os.path.join(file_path_data, r\"dayahead_Jan_365days.csv\")\n",
    "    P_spot_df = pd.read_csv(file_path, index_col=0,\n",
    "                            parse_dates=[0], date_format=date_format_str)  # to make sure the date is read properly\n",
    "    P_spot_df.index = P_spot_df.index.to_pydatetime() # convert to a datetime format required for the model\n",
    "    P_spot_df = P_spot_df[[\"day ahead price (p/kWh)\"]]  # get only price in pences/kWh\n",
    "    P_spot_df_ = P_spot_df[(P_spot_df.index >= start_date) & (P_spot_df.index < end_date)]\n",
    "    # Convert the dataframe P_spot_df_ to dictionary for data input for the function model_p2p()\n",
    "    P_spot = P_spot_df_.to_dict()\n",
    "\n",
    "    # Get demand\n",
    "    demand_ = demand[list_houses]  # Filter based on the houses selected\n",
    "    demand_ = demand_.stack()  # Set time and household as index\n",
    "    # Convert the dataframe to dictionary\n",
    "    P_demand = demand_.to_dict()\n",
    "\n",
    "    # Get solar profiles, we assume the PV profile is the same for each house given that they are located close to each other\n",
    "    file_path = os.path.join(file_path_data, r\"solar_profile_scenarios_yearly.csv\")\n",
    "    PV_df = pd.read_csv(file_path, index_col=0,\n",
    "                        parse_dates=[0], date_format=date_format_str)\n",
    "    PV_df.index = PV_df.index.to_pydatetime() # convert to a datetime format required for the model\n",
    "    scn = \"1\"\n",
    "    PV_df = PV_df[[scn]]  # Select just one scenario, the data is prepared for several scenarios\n",
    "    PV_df_ = PV_df[(PV_df.index >= start_date) & (PV_df.index < end_date)]\n",
    "    # Convert the dataframe to dictionary\n",
    "    PV = PV_df_.to_dict()\n",
    "\n",
    "    # Set T\n",
    "    list_T = P_spot_df_.index.to_list()\n",
    "\n",
    "    # Parameter PV_cap\n",
    "    PV_cap = {f\"{key}\":capacity_pv[i] for i, key in enumerate(list_houses_pv)}\n",
    "\n",
    "    # Scalars (single value parameters)\n",
    "    Psi = 1 - 0.076  # Losses (assume a loss of 7.6% through the local network, Luth)\n",
    "    Mu_c = 0.96  # Charging efficiency\n",
    "    Mu_d = 0.96  # Discharging efficiency\n",
    "    Alpha = 1.5  # charging rate 2.5 kW -> 1.25 kWh/hour at constant rate\n",
    "    Beta = 1.5  # discharging rate 2.5 kW -> 1.25 kWh/hour at constant rate\n",
    "    Smax = 4  # capacity batteries [kWh] # It can also be changes to be similar to parameter PV_cap where you specify the capacity of each battery\n",
    "    Smin = Smax * 0.2  # minimum state of charge of batteries at all times\n",
    "    S_init = Smax * 0.5  # initial state of charge of the battery\n",
    "    c_FFR = 1000\n",
    "\n",
    "    # Construct data dictionary\n",
    "    data = {  # always start with None and then dictionary\n",
    "        None: {  # names of the keys equal to the name of the parameteres in the model\n",
    "            'H': {None: list_houses},  # providing data for set H\n",
    "            'H_pv': {None: list_houses_pv},  # providing data for set H_pv\n",
    "            \"H_bat\": {None: list_houses_bat},  # providing data for set H_bat\n",
    "            \"T\": {None: list_T},  # providing datetime for set T\n",
    "            # Parameters\n",
    "            'P_spot': P_spot['day ahead price (p/kWh)'],\n",
    "            \"PV\": PV[scn],\n",
    "            \"PV_cap\": PV_cap,\n",
    "            \"Dem\": P_demand,\n",
    "            # Scalars\n",
    "            \"Psi\": {None: Psi},\n",
    "            \"Mu_c\": {None: Mu_c},\n",
    "            \"Mu_d\": {None: Mu_d},\n",
    "            \"Alpha\": {None: Alpha},\n",
    "            \"Beta\": {None: Beta},\n",
    "            \"Smax\": {None: Smax},\n",
    "            \"Smin\": {None: Smin},\n",
    "            \"S_init\": {None: S_init},\n",
    "            \"c_FFR\": {None: c_FFR}\n",
    "        }}\n",
    "\n",
    "    return data\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c12329f9af33889",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computations for tree 2-X"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bdb3d5302319bc0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# generate clusters according to tree\n",
    "n_clusters = 2\n",
    "sil_score_dict, sample_silhouette_values_dict, centers_dict = SilhouetteScoreRange(array=demand_array, nClusters = n_clusters)\n",
    "dataKMeans, dataProcessed = KMeansAlgorithm(array=demand_array, dataframe=demand_, nClusters=n_clusters)\n",
    "\n",
    "# Get agents ordered and number of agents in each node. Note that the tree only has two layers\n",
    "agents_list, agents = agents_preprocessing(dataKMeans) # agents_list contains the name of the agent and the element it corresponds\n",
    "demand = demand[agents_list] # reorganise the demand to match the clustering tree\n",
    "\n",
    "# Prepare ordered tree\n",
    "tree_layers = [2,6,0] # number of children nodes per node\n",
    "special_layer_index = 1  # Index of the special layer (0-based). This layer does not have the number of children node indicated in tree_layers\n",
    "\n",
    "Ci_list = create_Ci_list(tree_layers, special_layer=special_layer_index, special_children=list(agents))\n",
    "Ci = get_Ci_matrix(Ci_list)\n",
    "\n",
    "# Construct the necessary matrices for computing appropriately the Nested Shapley. See basic_shapley.py for a simple example.\n",
    "N_M_list = create_N_M_list(Ci_list, Ci)\n",
    "N_M = get_NM_matrix(N_M_list)\n",
    "\n",
    "VS = get_VS_matrix(Ci)\n",
    "\n",
    "A = np.dot(VS,N_M)\n",
    "\n",
    "dataKMeans[\"predicted cluster\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aabdb2fc0c38f9af",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Case 1: Different agent contribution\n",
    "\n",
    "In Case 1, we explore the case where agents do not contribute equally in terms of generation and storage technologies. Those community members owning these technologies are indicated by the variables `houses_pv` and `houses_bat`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb765cde818fa7c5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the characteristic function for case with all agents contributing the same\n",
    "# Initialise v to save the characteristic functions of each subcoalition\n",
    "v = np.zeros(len(A))\n",
    "for row in range(len(A)):\n",
    "    print(f\"Run {row} of {len(A)}\")\n",
    "    current_agents_index = A[row]\n",
    "    current_agents = [agent for i, agent in enumerate(agents_list) if current_agents_index[i]==1]\n",
    "\n",
    "    n_houses = np.sum(current_agents == 1)\n",
    "\n",
    "    # Create dictionary of data with function generate_data_dict()\n",
    "    data = generate_data_dict_case_1(file_path_data, start_date_str, end_date_str, demand, current_agents, houses_pv, houses_bat)\n",
    "\n",
    "    # Run the model\n",
    "    instance = model_p2p(data)\n",
    "    v[row] = instance.objective_function.expr()\n",
    "\n",
    "# Activate to save the value functions in a csv file\n",
    "#np.savetxt(r\"v_NestedShapley.csv\", v, delimiter=\",\", fmt=\"%f\")\n",
    "\n",
    "nodal_shapley = get_shapley_node(Ci, A, VS, v)\n",
    "nested_shapley_node = get_approx_shapley_node(Ci, nodal_shapley)\n",
    "nested_shapley_agents = associate_shapley_agent(N_M=N_M, approx_shapley_node=nested_shapley_node)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0786fd89401cd43",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"For Case 1: Different agent contribution\")\n",
    "print(\"The Nested Shapley values of the agents are: \\n\")\n",
    "for i, agent in enumerate(agents_list):\n",
    "    print(f\"Agent {agent}: {nested_shapley_agents[i].round(1)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f38773e0a7feddb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Case 2: Equal agent contribution\n",
    "\n",
    "In this case study, we assume every house contributes equally to the coalition in storage and generation technologies. Each agent is assumed to own a PV panel of 5 kW and a storage technology of 4 kWh."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46dd64fffcce5927"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the characteristic function for case with all agents contributing the same\n",
    "# Initialise v to save the characteristic functions of each subcoalition\n",
    "v = np.zeros(len(A))\n",
    "for row in range(len(A)):\n",
    "    print(f\"Run {row} of {len(A)}\")\n",
    "    current_agents_index = A[row]\n",
    "    current_agents = [agent for i, agent in enumerate(agents_list) if current_agents_index[i]==1]\n",
    "\n",
    "    n_houses = np.sum(current_agents == 1)\n",
    "\n",
    "    # Create dictionary of data with function generate_data_dict()\n",
    "    data = generate_data_dict_case_2(file_path_data, start_date_str, end_date_str, demand, current_agents)\n",
    "\n",
    "    # Run the model\n",
    "    instance = model_p2p(data)\n",
    "    v[row] = instance.objective_function.expr()\n",
    "\n",
    "# Activate to save the value functions in a csv file\n",
    "#np.savetxt(r\"v_NestedShapley.csv\", v, delimiter=\",\", fmt=\"%f\")\n",
    "\n",
    "nodal_shapley = get_shapley_node(Ci, A, VS, v)\n",
    "nested_shapley_node = get_approx_shapley_node(Ci, nodal_shapley)\n",
    "nested_shapley_agents = associate_shapley_agent(N_M=N_M, approx_shapley_node=nested_shapley_node)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "247e5634542cc59e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"For Case 2: Equal agent contribution\")\n",
    "print(\"The Nested Shapley values of the agents are: \\n\")\n",
    "for i, agent in enumerate(agents_list):\n",
    "    print(f\"Agent {agent}: {nested_shapley_agents[i].round(1)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aaef0643b3b24675",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computations for tree 3-X"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d7e787e28580e9e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# generate clusters according to tree\n",
    "n_clusters = 3\n",
    "sil_score_dict, sample_silhouette_values_dict, centers_dict = SilhouetteScoreRange(array=demand_array, nClusters = n_clusters)\n",
    "dataKMeans, dataProcessed = KMeansAlgorithm(array=demand_array, dataframe=demand_, nClusters=n_clusters)\n",
    "\n",
    "# Get agents ordered and number of agents in each node\n",
    "agents_list, agents = agents_preprocessing(dataKMeans) # agents_list contains the name of the agent and the element it corresponds\n",
    "demand = demand[agents_list] # reorganise the demand to match the clustering tree\n",
    "\n",
    "# Prepare ordered tree\n",
    "tree_layers = [3,5,0]\n",
    "special_layer_index = 1  # Index of the special layer (0-based)\n",
    "\n",
    "Ci_list = create_Ci_list(tree_layers, special_layer=special_layer_index, special_children=list(agents))\n",
    "Ci = get_Ci_matrix(Ci_list)\n",
    "\n",
    "# Construct the necessary matrices for computing appropriately the Nested Shapley. See basic_shapley.py for a simple example.\n",
    "N_M_list = create_N_M_list(Ci_list, Ci)\n",
    "N_M = get_NM_matrix(N_M_list)\n",
    "\n",
    "VS = get_VS_matrix(Ci)\n",
    "\n",
    "A = np.dot(VS,N_M)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd885d52e430352e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Case 1: Different agent contribution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbbd23c4eaadc480"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the characteristic function\n",
    "# Initialise v to save the characteristic functions of each subcoalition\n",
    "v = np.zeros(len(A))\n",
    "for row in range(len(A)):\n",
    "    print(f\"Run {row} of {len(A)}\")\n",
    "    current_agents_index = A[row]\n",
    "    current_agents = [agent for i, agent in enumerate(agents_list) if current_agents_index[i]==1]\n",
    "\n",
    "    n_houses = np.sum(current_agents == 1)\n",
    "\n",
    "    # Create dictionary of data with function generate_data_dict_case_1()\n",
    "    data = generate_data_dict_case_1(file_path_data, start_date_str, end_date_str, demand, current_agents, houses_pv, houses_bat)\n",
    "\n",
    "    # Run the model\n",
    "    instance = model_p2p(data)\n",
    "    v[row] = instance.objective_function.expr()\n",
    "\n",
    "# Activate to save the value functions in a csv file\n",
    "#np.savetxt(r\"v_NestedShapley.csv\", v, delimiter=\",\", fmt=\"%f\")\n",
    "\n",
    "nodal_shapley = get_shapley_node(Ci, A, VS, v)\n",
    "nested_shapley_node = get_approx_shapley_node(Ci, nodal_shapley)\n",
    "nested_shapley_agents = associate_shapley_agent(N_M=N_M, approx_shapley_node=nested_shapley_node)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6888c13514573e0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"For Case 1: Different agent contribution\")\n",
    "print(\"The Nested Shapley values of the agents are: \\n\")\n",
    "for i, agent in enumerate(agents_list):\n",
    "    print(f\"Agent {agent}: {nested_shapley_agents[i].round(1)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1a0c9088b733ee9",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Case 2: Equal agent contribution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "940d68d524cb2768"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the characteristic function for case with all agents contributing the same\n",
    "# Initialise v to save the characteristic functions of each subcoalition\n",
    "v = np.zeros(len(A))\n",
    "for row in range(len(A)):\n",
    "    print(f\"Run {row} of {len(A)}\")\n",
    "    current_agents_index = A[row]\n",
    "    current_agents = [agent for i, agent in enumerate(agents_list) if current_agents_index[i]==1]\n",
    "\n",
    "    n_houses = np.sum(current_agents == 1)\n",
    "\n",
    "    # Create dictionary of data with function generate_data_dict()\n",
    "    data = generate_data_dict_case_2(file_path_data, start_date_str, end_date_str, demand, current_agents)\n",
    "\n",
    "    # Run the model\n",
    "    instance = model_p2p(data)\n",
    "    v[row] = instance.objective_function.expr()\n",
    "\n",
    "# Activate to save the value functions in a csv file\n",
    "#np.savetxt(r\"v_NestedShapley.csv\", v, delimiter=\",\", fmt=\"%f\")\n",
    "\n",
    "nodal_shapley = get_shapley_node(Ci, A, VS, v)\n",
    "nested_shapley_node = get_approx_shapley_node(Ci, nodal_shapley)\n",
    "nested_shapley_agents = associate_shapley_agent(N_M=N_M, approx_shapley_node=nested_shapley_node)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3df5019425500adf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"For Case 2: Equal agent contribution\")\n",
    "print(\"The Nested Shapley values of the agents are: \\n\")\n",
    "for i, agent in enumerate(agents_list):\n",
    "    print(f\"Agent {agent}: {nested_shapley_agents[i].round(1)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e30e9fd60e910320",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computations for tree 4-X"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cae670f33ceed6eb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# generate clusters according to tree\n",
    "n_clusters = 4\n",
    "sil_score_dict, sample_silhouette_values_dict, centers_dict = SilhouetteScoreRange(array=demand_array, nClusters = n_clusters)\n",
    "dataKMeans, dataProcessed = KMeansAlgorithm(array=demand_array, dataframe=demand_, nClusters=n_clusters)\n",
    "\n",
    "# Get agents ordered and number of agents in each node\n",
    "agents_list, agents = agents_preprocessing(dataKMeans) # agents_list contains the name of the agent and the element it corresponds\n",
    "demand = demand[agents_list] # reorganise the demand to match the clustering tree\n",
    "\n",
    "# Prepare ordered tree\n",
    "tree_layers = [4,3,0]\n",
    "special_layer_index = 1  # Index of the special layer (0-based)\n",
    "\n",
    "Ci_list = create_Ci_list(tree_layers, special_layer=special_layer_index, special_children=list(agents))\n",
    "Ci = get_Ci_matrix(Ci_list)\n",
    "\n",
    "# Construct the necessary matrices for computing appropriately the Nested Shapley. See basic_shapley.py for a simple example.\n",
    "N_M_list = create_N_M_list(Ci_list, Ci)\n",
    "N_M = get_NM_matrix(N_M_list)\n",
    "\n",
    "VS = get_VS_matrix(Ci)\n",
    "\n",
    "A = np.dot(VS,N_M)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b655ee19ae8d0590"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Case 1: Different agent contribution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "920693411d8d4162"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the characteristic function\n",
    "# Initialise v to save the characteristic functions of each subcoalition\n",
    "v = np.zeros(len(A))\n",
    "for row in range(len(A)):\n",
    "    print(f\"Run {row} of {len(A)}\")\n",
    "    current_agents_index = A[row]\n",
    "    current_agents = [agent for i, agent in enumerate(agents_list) if current_agents_index[i]==1]\n",
    "\n",
    "    n_houses = np.sum(current_agents == 1)\n",
    "\n",
    "    # Create dictionary of data with function generate_data_dict_case_1()\n",
    "    data = generate_data_dict_case_1(file_path_data, start_date_str, end_date_str, demand, current_agents, houses_pv, houses_bat)\n",
    "\n",
    "    # Run the model\n",
    "    instance = model_p2p(data)\n",
    "    v[row] = instance.objective_function.expr()\n",
    "\n",
    "# Activate to save the value functions in a csv file\n",
    "#np.savetxt(r\"v_NestedShapley.csv\", v, delimiter=\",\", fmt=\"%f\")\n",
    "\n",
    "nodal_shapley = get_shapley_node(Ci, A, VS, v)\n",
    "nested_shapley_node = get_approx_shapley_node(Ci, nodal_shapley)\n",
    "nested_shapley_agents = associate_shapley_agent(N_M=N_M, approx_shapley_node=nested_shapley_node)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3587c2863c939b9c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"For Case 1: Different agent contribution\")\n",
    "print(\"The Nested Shapley values of the agents are: \\n\")\n",
    "for i, agent in enumerate(agents_list):\n",
    "    print(f\"Agent {agent}: {nested_shapley_agents[i].round(1)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d30c64bf63733821"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Case 2: Equal agent contribution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30b8222acbeec366"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the characteristic function for case with all agents contributing the same\n",
    "# Initialise v to save the characteristic functions of each subcoalition\n",
    "v = np.zeros(len(A))\n",
    "for row in range(len(A)):\n",
    "    print(f\"Run {row} of {len(A)}\")\n",
    "    current_agents_index = A[row]\n",
    "    current_agents = [agent for i, agent in enumerate(agents_list) if current_agents_index[i]==1]\n",
    "\n",
    "    n_houses = np.sum(current_agents == 1)\n",
    "\n",
    "    # Create dictionary of data with function generate_data_dict()\n",
    "    data = generate_data_dict_case_2(file_path_data, start_date_str, end_date_str, demand, current_agents)\n",
    "\n",
    "    # Run the model\n",
    "    instance = model_p2p(data)\n",
    "    v[row] = instance.objective_function.expr()\n",
    "\n",
    "# Activate to save the value functions in a csv file\n",
    "#np.savetxt(r\"v_NestedShapley.csv\", v, delimiter=\",\", fmt=\"%f\")\n",
    "\n",
    "nodal_shapley = get_shapley_node(Ci, A, VS, v)\n",
    "nested_shapley_node = get_approx_shapley_node(Ci, nodal_shapley)\n",
    "nested_shapley_agents = associate_shapley_agent(N_M=N_M, approx_shapley_node=nested_shapley_node)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "305d953808d54305"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"For Case 2: Equal agent contribution\")\n",
    "print(\"The Nested Shapley values of the agents are: \\n\")\n",
    "for i, agent in enumerate(agents_list):\n",
    "    print(f\"Agent {agent}: {nested_shapley_agents[i].round(1)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa04893a906991f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computations for tree 6-X"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33c9752deffabb9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# generate clusters according to tree\n",
    "n_clusters = 6\n",
    "sil_score_dict, sample_silhouette_values_dict, centers_dict = SilhouetteScoreRange(array=demand_array, nClusters = n_clusters)\n",
    "dataKMeans, dataProcessed = KMeansAlgorithm(array=demand_array, dataframe=demand_, nClusters=n_clusters)\n",
    "\n",
    "# Get agents ordered and number of agents in each node\n",
    "agents_list, agents = agents_preprocessing(dataKMeans) # agents_list contains the name of the agent and the element it corresponds\n",
    "demand = demand[agents_list] # reorganise the demand to match the clustering tree\n",
    "\n",
    "# Prepare ordered tree. This case manually created based on the results from the k-means algorithm\n",
    "Ci_list = [\n",
    "    [2,3,4,5,6,7],\n",
    "    [8,9,10],\n",
    "    [11,12,13],\n",
    "    [14,15],\n",
    "    [16,17],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    []\n",
    "]\n",
    "\n",
    "Ci = get_Ci_matrix(Ci_list)\n",
    "\n",
    "N_M_list = [\n",
    "    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    " [1, 2, 3],\n",
    " [4, 5, 6],\n",
    " [7, 8],\n",
    " [9, 10],\n",
    " [11],\n",
    " [12],\n",
    " [1],\n",
    " [2],\n",
    " [3],\n",
    " [4],\n",
    " [5],\n",
    " [6],\n",
    " [7],\n",
    " [8],\n",
    " [9],\n",
    " [10]]\n",
    "\n",
    "# Construct the necessary matrices for computing appropriately the Nested Shapley. See basic_shapley.py for a simple example.\n",
    "N_M_list = create_N_M_list(Ci_list, Ci)\n",
    "N_M = get_NM_matrix(N_M_list)\n",
    "\n",
    "VS = get_VS_matrix(Ci)\n",
    "\n",
    "A = np.dot(VS,N_M)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4aba2df2d0accaaa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Case 1: Different agent contribution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2107d98a8e358dc3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the characteristic function\n",
    "# Initialise v to save the characteristic functions of each subcoalition\n",
    "v = np.zeros(len(A))\n",
    "for row in range(len(A)):\n",
    "    print(f\"Run {row} of {len(A)}\")\n",
    "    current_agents_index = A[row]\n",
    "    current_agents = [agent for i, agent in enumerate(agents_list) if current_agents_index[i]==1]\n",
    "\n",
    "    n_houses = np.sum(current_agents == 1)\n",
    "\n",
    "    # Create dictionary of data with function generate_data_dict_case_1()\n",
    "    data = generate_data_dict_case_1(file_path_data, start_date_str, end_date_str, demand, current_agents, houses_pv, houses_bat)\n",
    "\n",
    "    # Run the model\n",
    "    instance = model_p2p(data)\n",
    "    v[row] = instance.objective_function.expr()\n",
    "\n",
    "# Activate to save the value functions in a csv file\n",
    "#np.savetxt(r\"v_NestedShapley.csv\", v, delimiter=\",\", fmt=\"%f\")\n",
    "\n",
    "nodal_shapley = get_shapley_node(Ci, A, VS, v)\n",
    "nested_shapley_node = get_approx_shapley_node(Ci, nodal_shapley)\n",
    "nested_shapley_agents = associate_shapley_agent(N_M=N_M, approx_shapley_node=nested_shapley_node)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4eb707143226cdf9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"For Case 1: Different agent contribution\")\n",
    "print(\"The Nested Shapley values of the agents are: \\n\")\n",
    "for i, agent in enumerate(agents_list):\n",
    "    print(f\"Agent {agent}: {nested_shapley_agents[i].round(1)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdb376892afbe075"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Case 2: Equal agent contribution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "476e75f7ab3bed39"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the characteristic function for case with all agents contributing the same\n",
    "# Initialise v to save the characteristic functions of each subcoalition\n",
    "v = np.zeros(len(A))\n",
    "for row in range(len(A)):\n",
    "    print(f\"Run {row} of {len(A)}\")\n",
    "    current_agents_index = A[row]\n",
    "    current_agents = [agent for i, agent in enumerate(agents_list) if current_agents_index[i]==1]\n",
    "\n",
    "    n_houses = np.sum(current_agents == 1)\n",
    "\n",
    "    # Create dictionary of data with function generate_data_dict()\n",
    "    data = generate_data_dict_case_2(file_path_data, start_date_str, end_date_str, demand, current_agents)\n",
    "\n",
    "    # Run the model\n",
    "    instance = model_p2p(data)\n",
    "    v[row] = instance.objective_function.expr()\n",
    "\n",
    "# Activate to save the value functions in a csv file\n",
    "#np.savetxt(r\"v_NestedShapley.csv\", v, delimiter=\",\", fmt=\"%f\")\n",
    "\n",
    "nodal_shapley = get_shapley_node(Ci, A, VS, v)\n",
    "nested_shapley_node = get_approx_shapley_node(Ci, nodal_shapley)\n",
    "nested_shapley_agents = associate_shapley_agent(N_M=N_M, approx_shapley_node=nested_shapley_node)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dae82a96ae7a34ae"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"For Case 2: Equal agent contribution\")\n",
    "print(\"The Nested Shapley values of the agents are: \\n\")\n",
    "for i, agent in enumerate(agents_list):\n",
    "    print(f\"Agent {agent}: {nested_shapley_agents[i].round(1)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6be82a6b8445dc9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computations for tree 8-X"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93c672ee2dfde6fb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# generate clusters according to tree\n",
    "n_clusters = 8\n",
    "sil_score_dict, sample_silhouette_values_dict, centers_dict = SilhouetteScoreRange(array=demand_array, nClusters = n_clusters)\n",
    "dataKMeans, dataProcessed = KMeansAlgorithm(array=demand_array, dataframe=demand_, nClusters=n_clusters)\n",
    "\n",
    "# Get agents ordered and number of agents in each node\n",
    "agents_list, agents = agents_preprocessing(dataKMeans) # agents_list contains the name of the agent and the element it corresponds\n",
    "demand = demand[agents_list] # reorganise the demand to match the clustering tree\n",
    "\n",
    "# Prepare ordered tree. This case manually created based on the results from the k-means algorithm\n",
    "Ci_list = [\n",
    "    [2,3,4,5,6,7,8,9],\n",
    "    [10, 11, 12],\n",
    "    [13, 14],\n",
    "    [15, 16],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    []\n",
    "]\n",
    "\n",
    "Ci = get_Ci_matrix(Ci_list)\n",
    "\n",
    "N_M_list = [\n",
    "    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    " [1, 2, 3],\n",
    " [4, 5],\n",
    " [6, 7],\n",
    " [8],\n",
    " [9],\n",
    " [10],\n",
    " [11],\n",
    " [12],\n",
    " [1],\n",
    " [2],\n",
    " [3],\n",
    " [4],\n",
    " [5],\n",
    " [6],\n",
    " [7]]\n",
    "\n",
    "# Construct the necessary matrices for computing appropriately the Nested Shapley. See basic_shapley.py for a simple example.\n",
    "N_M_list = create_N_M_list(Ci_list, Ci)\n",
    "N_M = get_NM_matrix(N_M_list)\n",
    "\n",
    "VS = get_VS_matrix(Ci)\n",
    "\n",
    "A = np.dot(VS,N_M)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9fc0c10a9da0dc6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Case 1: Different agent contribution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c460523982dfff9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the characteristic function\n",
    "# Initialise v to save the characteristic functions of each subcoalition\n",
    "v = np.zeros(len(A))\n",
    "for row in range(len(A)):\n",
    "    print(f\"Run {row} of {len(A)}\")\n",
    "    current_agents_index = A[row]\n",
    "    current_agents = [agent for i, agent in enumerate(agents_list) if current_agents_index[i]==1]\n",
    "\n",
    "    n_houses = np.sum(current_agents == 1)\n",
    "\n",
    "    # Create dictionary of data with function generate_data_dict_case_1()\n",
    "    data = generate_data_dict_case_1(file_path_data, start_date_str, end_date_str, demand, current_agents, houses_pv, houses_bat)\n",
    "\n",
    "    # Run the model\n",
    "    instance = model_p2p(data)\n",
    "    v[row] = instance.objective_function.expr()\n",
    "\n",
    "# Activate to save the value functions in a csv file\n",
    "#np.savetxt(r\"v_NestedShapley.csv\", v, delimiter=\",\", fmt=\"%f\")\n",
    "\n",
    "nodal_shapley = get_shapley_node(Ci, A, VS, v)\n",
    "nested_shapley_node = get_approx_shapley_node(Ci, nodal_shapley)\n",
    "nested_shapley_agents = associate_shapley_agent(N_M=N_M, approx_shapley_node=nested_shapley_node)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfeee699d6fbf076"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"For Case 1: Different agent contribution\")\n",
    "print(\"The Nested Shapley values of the agents are: \\n\")\n",
    "for i, agent in enumerate(agents_list):\n",
    "    print(f\"Agent {agent}: {nested_shapley_agents[i].round(1)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9500460b6078358e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Case 2: Equal agent contribution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "766425c478d36155"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the characteristic function for case with all agents contributing the same\n",
    "# Initialise v to save the characteristic functions of each subcoalition\n",
    "v = np.zeros(len(A))\n",
    "for row in range(len(A)):\n",
    "    print(f\"Run {row} of {len(A)}\")\n",
    "    current_agents_index = A[row]\n",
    "    current_agents = [agent for i, agent in enumerate(agents_list) if current_agents_index[i]==1]\n",
    "\n",
    "    n_houses = np.sum(current_agents == 1)\n",
    "\n",
    "    # Create dictionary of data with function generate_data_dict()\n",
    "    data = generate_data_dict_case_2(file_path_data, start_date_str, end_date_str, demand, current_agents)\n",
    "\n",
    "    # Run the model\n",
    "    instance = model_p2p(data)\n",
    "    v[row] = instance.objective_function.expr()\n",
    "\n",
    "# Activate to save the value functions in a csv file\n",
    "#np.savetxt(r\"v_NestedShapley.csv\", v, delimiter=\",\", fmt=\"%f\")\n",
    "\n",
    "nodal_shapley = get_shapley_node(Ci, A, VS, v)\n",
    "nested_shapley_node = get_approx_shapley_node(Ci, nodal_shapley)\n",
    "nested_shapley_agents = associate_shapley_agent(N_M=N_M, approx_shapley_node=nested_shapley_node)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cea83c7378fc6189"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"For Case 2: Equal agent contribution\")\n",
    "print(\"The Nested Shapley values of the agents are: \\n\")\n",
    "for i, agent in enumerate(agents_list):\n",
    "    print(f\"Agent {agent}: {nested_shapley_agents[i].round(1)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc4363b1066e3204"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "497a8b8221f68e0d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
